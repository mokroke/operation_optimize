signate_diary_1

10/1 
まずデータを確認してみようかなって思う
予測部門のチュートリアルもあるからだいぶわかりやすくなってんなと思う

使用ファイル
No.1_eda.ipynb　


10/2
signateの公式が出している、Student Cup 2021秋 予測部門 チュートリアルを読んだ。
EDAもかなりしっかりしているから、序盤はこれをしっかり理解するところから始めるのが重要かもしれない
一回公式をなぞってみようかなって思った。
使用ファイル


10/3 
signateのホームページでデータの内容を確認した。
cvが難しそうだなっていうイメージがある


10/4
signateのフォーラムをコピーしながらvalidationに手を加えようと思って,
classを作った。まだうまく動かないけど、動けばいい感じかなと思う
使用ファイル
No_1_copy.ipynb No_2_copy.ipynb


10/5
signateのフォーラムのコピーからの続き。
validationのclassが完成して、提出したら、PBが3.5897336で10位にきた。
まだ序盤だからわからないけど、なんか楽しいね。
おそらく特徴量でまだ入れられてないところがあるからその辺も入れてやろうかなって思う。
CVのスコアをまだ出す仕組みを整えられてないし、クラスの整理もできてないから、その辺を明日はやっていけたらいいかな
使用ファイル
No_2_copy.ipynb


10/6
cvを出すことのできるクラスを作った。  
あとはmodel保存とかをして、色々特徴量を作っていこうと思う。
それによったフィードバックをして、データの特性をつかんで行けたらなと思う。
使用ファイル
No_1_my.ipynb


10/7
モデルの保存方法とか、結果の保存を大事にしていきたいなと思っている。どうしよ。
(https://localab.jp/blog/save-and-load-machine-learning-models-in-python-with-scikit-learn/)モデルの保存はこのサイトを参考にした。
(https://watlab-blog.com/2020/01/01/ml-pickle/)わかりやすい。

使用ファイル
No_1_my.ipynb  No_2_my.ipynb(いろんなモデルで遊ぶ)


10/8
命名規則の変更とリレー方式のモデルにした
modelの名前とsubmitは一対一対応にしたいな
なんでdataframe読み込んでるはずなのに0,1になるんだろ。
二つのretunになっていない気がする make_fit_modelのとこ
重回帰分析はsubmission_0_No_4_my.csv
ラッソ回帰はsubmission_1_No_4_my.csv
リッジ回帰はsubmission_2_No_4_my.csv
エラスティックネットはsubmission_3_No_4_my.csv
決定木はsubmission_4_No_4_my.csv

10/9
今日はLSTM,biLSTMを使えないか色々やってみようと思う
https://github.com/SnowMasaya/time_series_anomaly_detect_hands_on/blob/master/advanced/time_series_anomaly_detect_keras_multivariate.ipynb
このソースコードでやってみたい

使用ファイル
No_5_my.ipynb

10/10
LSTMを使いたくて、Youtubuで解説動画を見てた。まだよくわからないけど、使えたら楽しそうだなと思う。やってる間に脳が停止して寝ちゃった。

10/11
引き続きLSTMについて勉強してた。今はディープラーニングの基礎から見てる
チュートリアルのNo.2が上がった。ちょうど勉強してたLSTMだった。一歩遅かった。悔しい
でもこれを使って大幅な精度向上を目指していきたい。
LSTMを使用するときにはどれくらい昔のデータまで利用するかが大事らしい
ステーション数70個、24時間分で1680個のデータが一回の予測で必要になる。


使用ファイル No_3_copy

10/12
今日は引き続きチュートリアルの解読をしてた。最後までもう少しだからこの調子で理解し終わって、自分でモデルを作っていきたい
使用ファイル No_3_copy

10/13
チュートリアルを一通り理解し終わった。
その上でLSTMはやっぱり難しいわ。結局意味がわからないとどう応用していいのかわからないから、応用を聞かせることができなそうだなと思った。一応今できる戦略かなと思うのは特徴量を増やして、さらに補完を前の値で埋めるんじゃなくて、LGBMでやったら少しは精度上がるのかなと思った。
自分がこれだったら上がりそうだなということは精度は低いかもしれないけど、愚直にやっていくことで伸びることもあると思うから、いつ成果が上がるかわからないけど重要なLSTMをやりつつ、成果が微増するのはわかってるけどそんなには大きく伸びなそうなものをめんどくさいけど成果が見えるからやってみるというのも織り交ぜていくといいのかなと思った。
stationの特徴量の改善と、tripの特徴量の改善をしてみた。lightgbmでどう変わるのか楽しみ。
余計な情報を入れたからなのか、lgbの精度が悪くなった
使用ファイル No_3_copy No_6_my

10/15
久しぶりに戻ってきたみたいな感じだね
特徴量を改善して動くようにした。めっちゃ期待してる楽しみ　脳汁がでた
線形変換、時差のデータの追加、
使用ファイル　No_6_my

10/16
お疲れ様
今日はモデルをさらに良くするために変数変換をしようと思った
クラスを作るときにいろんな変数変換に対応できたらいいなと思ったからその仕組みについてアイデアを出してたね。残り少ない期間でできることは、自分の能力を最大限に活かすことだから、少しずつ実装していきたい。
使用ファイル　No_6_my

10/17
標準化、正規化、ロバスト化、log化,yeo化
変数変換したけど、清々しいほどほとんど変わらん。
そりゃそーか。
使用ファイル　No_7_my

10/18
特徴量重要度をみたいねまず。
今回は3日くらいまでずらしたやつと、SVDの特徴量入れたいわ。
なんか、seglearnっていうやつで特徴量が抽出できるらしい。やってみよ。（https://cpp-learning.com/seglearn/）

10/19
もう30位くらいになってたわ。そろそろパラメーターチューニングの時期かな。
頑張ってパラメータチューニング、特徴量の抽出、LSTM、BiLSTMも試してみたい。

10/20
ハイパラのチューニングやろうと思ったけど、時間はかかりそうだなって思った。
実行はまだしないとして、ちょっとコーディングだけしようかな。
とりあえず、cvの高いやつとLBの高いやつ両方やろうかな。
使用ファイル
No_8_my.ipynb .... LB高いやつ
No_9_my.ipynb .... CV高いやつ

10/21
これ使ったらログが作れるようになるかも(https://qiita.com/dcm_hattori/items/fbe5750111de7e4484ea)
やってみたい
今回はoptunaのlightgbmバージョンがあるらしいからそれを使ってみた

10/23
昨日は話し込みすぎてスキップしちゃったね。
リーダーボードは35位まで落ち込んでるし、全然cvとあってない現状は変わってない。
最後はLSTMをちょっと適当にやって、記事書いて終わらせたいな。

10/24
lagを入れたやつでハイパラチューニングしたやつを入れてみた。
果たしてどうなるかな。

10/25
答えも入れながら予測したいよね

10/27
今日でコンペも終わり。
お疲れ様。
自分のできることはかなり精一杯できた。
これ以上上に行くにはもっとやることが必要だ。
日々精進だね。もっともっと強くなれる。


LBが高いやつを出したら銀圏だったのか。
泣いた。
くそお。
次は絶対勝ってやる。
待ってろよ。