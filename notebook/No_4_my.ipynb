{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb_path\n",
    "now_file_name = ipynb_path.get().split('/')[-1].replace('.ipynb','')\n",
    "\n",
    "input_path = '../input/'\n",
    "status_file_name = 'status.csv'\n",
    "station_file_name = 'station.csv'\n",
    "trip_file_name = 'trip.csv'\n",
    "weather_file_name = 'weather.csv'\n",
    "output_path = '../output/'\n",
    "model_path = '../model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "初めの数字を入力してください 0\n",
      "終わりの数字を入力してください 20\n"
     ]
    }
   ],
   "source": [
    "#実行したらコメントアウトする\n",
    "#保存ファイルの重複が起こる可能性がある\n",
    "###########################################################\n",
    "# もう一度notebookを動かす際はモデルリストのstart_numとend_numを\n",
    "# 設定してください\n",
    "###########################################################\n",
    "st_in = input('初めの数字を入力してください')\n",
    "end_in = input('終わりの数字を入力してください')\n",
    "start_num = int(st_in)\n",
    "end_num = int(end_in)\n",
    "\n",
    "model_name_list = [f'model_{i}_{now_file_name}.sav' for i in range(start_num, end_num)]\n",
    "submit_file_name_list = [f'submission_{i}_{now_file_name}.csv' for i in range(start_num,end_num)]\n",
    "model_submit_dict = dict(zip(model_name_list,submit_file_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_csv(input_path + status_file_name)\n",
    "station = pd.read_csv(input_path + station_file_name)\n",
    "weather = pd.read_csv(input_path + weather_file_name)\n",
    "\n",
    "\n",
    "#statusのyear, month, dayを結合してdatetime型に\n",
    "status['date'] = status['year'].astype(str) + '/' + status['month'].astype(str).str.zfill(2).astype(str) + '/' + status['day'].astype(str).str.zfill(2).astype(str)\n",
    "status['date'] = pd.to_datetime(status['date'])\n",
    "\n",
    "weather['date'] = pd.to_datetime(weather['date'])\n",
    "\n",
    "train_sta_wea = pd.merge(status,weather, on = 'date', how ='left')\n",
    "\n",
    "train_sta_wea['events'] = train_sta_wea['events'].fillna('なし')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_sta_wea['events'] = le.fit_transform(train_sta_wea['events'].values.tolist())\n",
    "train_sta_wea = pd.merge(train_sta_wea, station[['station_id', 'city']], how = 'left')\n",
    "\n",
    "train_sta_wea_pre_1 = train_sta_wea[train_sta_wea['predict'] == 1]\n",
    "\n",
    "train_sta_wea_pre_0 = train_sta_wea[train_sta_wea['predict'] == 0]\n",
    "\n",
    "#曜日を追加\n",
    "train_sta_wea['date']=pd.to_datetime(train_bsta_wea['date'])\n",
    "train_sta_wea['weekday']=train_sta_wea['date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重回帰分析\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "class make_tr_va_te():\n",
    "    def __init__(self, df, train_end_next_date):\n",
    "        self.df = df\n",
    "        self.train_end_next_date = train_end_next_date\n",
    "        \n",
    "    def make_train_data(self):\n",
    "        train_all = self.df[self.df['predict'] == 0]\n",
    "        train = train_all[train_all['date'] < self.train_end_next_date]\n",
    "        train_notna = train[train['bikes_available'].notna()]\n",
    "        return train_notna\n",
    "        \n",
    "    def make_valid_data(self):\n",
    "        valid_all = self.df[self.df['predict'] == 0]\n",
    "        valid = valid_all[(self.train_end_next_date <= valid_all['date']) & (valid_all['date'] < (self.train_end_next_date + relativedelta(months = 1)))]\n",
    "        valid_notna = valid[valid['bikes_available'].notna()]\n",
    "        return valid_notna\n",
    "                                      \n",
    "    def make_test_data(self):\n",
    "        test_all = self.df[self.df['predict'] == 1]\n",
    "        test = test_all[((self.train_end_next_date + relativedelta(months = 1)) <= test_all['date']) & (test_all['date']< (self.train_end_next_date + relativedelta(months = 2)))]\n",
    "        return test\n",
    "    \n",
    "    def model_for_data(self, train, valid):      \n",
    "        tr_X = train.drop(['id','predict','bikes_available','city','date'],axis=1)\n",
    "        tr_y = train['bikes_available']\n",
    "        va_X = valid.drop(['id','predict','bikes_available','city','date'],axis=1)\n",
    "        va_y = valid['bikes_available']   \n",
    "        return tr_X, tr_y, va_X, va_y\n",
    "    \n",
    "    def predict_for_data(self, test):\n",
    "        te_X = test.drop(['id','predict','bikes_available','city','date'],axis=1)       \n",
    "        return te_X\n",
    "    \n",
    "    def make_fit_model(self, tr_X, tr_y, va_X, va_y ):\n",
    "        model = LinearRegression()\n",
    "        model.fit(tr_X, tr_y)\n",
    "        return model\n",
    "    \n",
    "    def model_and_valid_score(self):\n",
    "        model = self.make_fit_model()\n",
    "        valid_best_score = model.best_score['valid_1']['rmse']\n",
    "        \n",
    "        return model, valid_best_score\n",
    "    \n",
    "    def predict(self, model_file_name):\n",
    "        import pickle\n",
    "        train = self.make_train_data()\n",
    "        valid = self.make_valid_data()\n",
    "        test = self.make_test_data()\n",
    "        tr_X, tr_y, va_X, va_y = self.model_for_data(train, valid)\n",
    "        te_X = self.predict_for_data(test)\n",
    "        model   = self.make_fit_model(tr_X, tr_y, va_X, va_y )\n",
    "        pickle.dump(model, open(model_path + model_file_name, 'wb')) \n",
    "        va_pred = model.predict(va_X)\n",
    "        y_pred = model.predict(te_X)\n",
    "        rmse_score = np.sqrt(mse(va_y,va_pred))\n",
    "        sub_index = test['id']\n",
    "        sub_df = pd.DataFrame(list(zip(sub_index, y_pred)))\n",
    "        print('*****')\n",
    "        print(rmse_score)\n",
    "        return sub_df, rmse_score\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_range(start, stop, step = relativedelta(months = 1)):\n",
    "    current = start\n",
    "    while current < stop:\n",
    "        yield current\n",
    "        current += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "3.9265042553556793\n",
      "*****\n",
      "4.0599377697046455\n",
      "*****\n",
      "4.319565186488821\n",
      "*****\n",
      "4.185624102513826\n",
      "*****\n",
      "4.450443588420891\n",
      "*****\n",
      "4.074178273797344\n",
      "*****\n",
      "4.302625917910384\n",
      "*****\n",
      "4.5189826472098416\n",
      "*****\n",
      "4.40707953796683\n",
      "*****\n",
      "4.302126506634736\n",
      "*****\n",
      "4.065503889854076\n",
      "*****\n",
      "3.94933292397741\n",
      "***\n",
      "***\n",
      "CV score is 4.213492049986207\n",
      "model_name is model_0_No_4_my.sav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_0_No_4_my.sav'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = make_data.make_fit_model(tr_X, tr_y, va_X, va_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "***\n",
      "CV score is 4.213492049986207\n",
      "model_name is model_0_No_4_my.sav\n"
     ]
    }
   ],
   "source": [
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_0_No_4_my.csv\n"
     ]
    }
   ],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsRegressor\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "class make_tr_va_te():\n",
    "    def __init__(self, df, train_end_next_date):\n",
    "        self.df = df\n",
    "        self.train_end_next_date = train_end_next_date\n",
    "        \n",
    "    def make_train_data(self):\n",
    "        train_all = self.df[self.df['predict'] == 0]\n",
    "        train = train_all[train_all['date'] < self.train_end_next_date]\n",
    "        train_notna = train[train['bikes_available'].notna()]\n",
    "        return train_notna\n",
    "        \n",
    "    def make_valid_data(self):\n",
    "        valid_all = self.df[self.df['predict'] == 0]\n",
    "        valid = valid_all[(self.train_end_next_date <= valid_all['date']) & (valid_all['date'] < (self.train_end_next_date + relativedelta(months = 1)))]\n",
    "        valid_notna = valid[valid['bikes_available'].notna()]\n",
    "        return valid_notna\n",
    "                                      \n",
    "    def make_test_data(self):\n",
    "        test_all = self.df[self.df['predict'] == 1]\n",
    "        test = test_all[((self.train_end_next_date + relativedelta(months = 1)) <= test_all['date']) & (test_all['date']< (self.train_end_next_date + relativedelta(months = 2)))]\n",
    "        return test\n",
    "    \n",
    "    def model_for_data(self, train, valid):      \n",
    "        tr_X = train.drop(['id','predict','bikes_available','city','date'],axis=1)\n",
    "        tr_y = train['bikes_available']\n",
    "        va_X = valid.drop(['id','predict','bikes_available','city','date'],axis=1)\n",
    "        va_y = valid['bikes_available']   \n",
    "        return tr_X, tr_y, va_X, va_y\n",
    "    \n",
    "    def predict_for_data(self, test):\n",
    "        te_X = test.drop(['id','predict','bikes_available','city','date'],axis=1)       \n",
    "        return te_X\n",
    "    \n",
    "    def make_fit_model(self, tr_X, tr_y, va_X, va_y ):\n",
    "        model = KNeighborsRegressor()\n",
    "        model.fit(tr_X, tr_y)\n",
    "        return model\n",
    "    \n",
    "    def model_and_valid_score(self):\n",
    "        model = self.make_fit_model()\n",
    "        valid_best_score = model.best_score['valid_1']['rmse']\n",
    "        \n",
    "        return model, valid_best_score\n",
    "    \n",
    "    def predict(self, model_file_name):\n",
    "        import pickle\n",
    "        train = self.make_train_data()\n",
    "        valid = self.make_valid_data()\n",
    "        test = self.make_test_data()\n",
    "        tr_X, tr_y, va_X, va_y = self.model_for_data(train, valid)\n",
    "        te_X = self.predict_for_data(test)\n",
    "        model   = self.make_fit_model(tr_X, tr_y, va_X, va_y )\n",
    "        pickle.dump(model, open(model_path + model_file_name, 'wb')) \n",
    "        va_pred = model.predict(va_X)\n",
    "        y_pred = model.predict(te_X)\n",
    "        rmse_score = np.sqrt(mse(va_y,va_pred))\n",
    "        sub_index = test['id']\n",
    "        sub_df = pd.DataFrame(list(zip(sub_index, y_pred)))\n",
    "        print('*****')\n",
    "        print(rmse_score)\n",
    "        return sub_df, rmse_score\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_range(start, stop, step = relativedelta(months = 1)):\n",
    "    current = start\n",
    "    while current < stop:\n",
    "        yield current\n",
    "        current += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-2c7eb7bd8628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msub_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_best_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msub_df_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_df_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalid_score_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_best_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-35ea7de42ba5>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model_file_name)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mva_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mrmse_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mva_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mva_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0msub_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[1;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0m\u001b[1;32m   1624\u001b[0m                                      n_jobs=n_jobs, **kwds)\n\u001b[1;32m   1625\u001b[0m         if ((X is Y or Y is None)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = make_data.make_fit_model(tr_X, tr_y, va_X, va_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#汎用可能にする\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "class make_tr_va_te():\n",
    "    def __init__(self, df, train_end_next_date):\n",
    "        self.df = df\n",
    "        self.train_end_next_date = train_end_next_date\n",
    "        \n",
    "    def make_train_data(self):\n",
    "        train_all = self.df[self.df['predict'] == 0]\n",
    "        train = train_all[train_all['date'] < self.train_end_next_date]\n",
    "        train_notna = train[train['bikes_available'].notna()]\n",
    "        return train_notna\n",
    "        \n",
    "    def make_valid_data(self):\n",
    "        valid_all = self.df[self.df['predict'] == 0]\n",
    "        valid = valid_all[(self.train_end_next_date <= valid_all['date']) & (valid_all['date'] < (self.train_end_next_date + relativedelta(months = 1)))]\n",
    "        valid_notna = valid[valid['bikes_available'].notna()]\n",
    "        return valid_notna\n",
    "                                      \n",
    "    def make_test_data(self):\n",
    "        test_all = self.df[self.df['predict'] == 1]\n",
    "        test = test_all[((self.train_end_next_date + relativedelta(months = 1)) <= test_all['date']) & (test_all['date']< (self.train_end_next_date + relativedelta(months = 2)))]\n",
    "        return test\n",
    "    \n",
    "    def model_for_data(self, train, valid):      \n",
    "        tr_X = train.drop(['id','predict','bikes_available','city','date'],axis=1)\n",
    "        tr_y = train['bikes_available']\n",
    "        va_X = valid.drop(['id','predict','bikes_available','city','date'],axis=1)\n",
    "        va_y = valid['bikes_available']   \n",
    "        return tr_X, tr_y, va_X, va_y\n",
    "    \n",
    "    def predict_for_data(self, test):\n",
    "        te_X = test.drop(['id','predict','bikes_available','city','date'],axis=1)       \n",
    "        return te_X\n",
    "    \n",
    "    def make_fit_model(self, tr_X, tr_y, va_X, va_y ):\n",
    "        model = KNeighborsRegressor()\n",
    "        model.fit(tr_X, tr_y)\n",
    "        return model\n",
    "    \n",
    "    def model_and_valid_score(self):\n",
    "        model = self.make_fit_model()\n",
    "        valid_best_score = model.best_score['valid_1']['rmse']\n",
    "        \n",
    "        return model, valid_best_score\n",
    "    \n",
    "    def predict(self, model, model_file_name):\n",
    "        import pickle\n",
    "        train = self.make_train_data()\n",
    "        valid = self.make_valid_data()\n",
    "        test = self.make_test_data()\n",
    "        tr_X, tr_y, va_X, va_y = self.model_for_data(train, valid)\n",
    "        te_X = self.predict_for_data(test)\n",
    "        pickle.dump(model, open(model_path + model_file_name, 'wb')) \n",
    "        va_pred = model.predict(va_X)\n",
    "        y_pred = model.predict(te_X)\n",
    "        rmse_score = np.sqrt(mse(va_y,va_pred))\n",
    "        sub_index = test['id']\n",
    "        sub_df = pd.DataFrame(list(zip(sub_index, y_pred)))\n",
    "        print('*****')\n",
    "        print(rmse_score)\n",
    "        return sub_df, rmse_score\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラッソ回帰\n",
    "from sklearn.linear_model import Lasso\n",
    "def model_lasso(tr_X, tr_y):\n",
    "    model = Lasso()\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "3.9315505671056528\n",
      "*****\n",
      "4.069846308212315\n",
      "*****\n",
      "4.331067409172134\n",
      "*****\n",
      "4.193090083497095\n",
      "*****\n",
      "4.44804331667126\n",
      "*****\n",
      "4.102317148986719\n",
      "*****\n",
      "4.323692564586363\n",
      "*****\n",
      "4.556095443206636\n",
      "*****\n",
      "4.42227588284393\n",
      "*****\n",
      "4.345449513107519\n",
      "*****\n",
      "4.092517202120235\n",
      "*****\n",
      "3.9422530954742605\n",
      "***\n",
      "***\n",
      "CV score is 4.229849877915343\n",
      "model_name is model_1_No_4_my.sav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_1_No_4_my.sav'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_lasso(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_2_No_4_my.csv\n"
     ]
    }
   ],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#リッジ回帰\n",
    "from sklearn.linear_model import Ridge\n",
    "def model_Ridge(tr_X, tr_y):\n",
    "    model = Ridge()\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "3.926489606947237\n",
      "*****\n",
      "4.059935481033495\n",
      "*****\n",
      "4.319568902943038\n",
      "*****\n",
      "4.185619696258506\n",
      "*****\n",
      "4.450431349019066\n",
      "*****\n",
      "4.074193800028289\n",
      "*****\n",
      "4.302626242272293\n",
      "*****\n",
      "4.518991466030281\n",
      "*****\n",
      "4.407061215308665\n",
      "*****\n",
      "4.302126856261457\n",
      "*****\n",
      "4.065493795813253\n",
      "*****\n",
      "3.9493074171232245\n",
      "***\n",
      "***\n",
      "CV score is 4.2134871524199005\n",
      "model_name is model_2_No_4_my.sav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_2_No_4_my.sav'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_Ridge(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_2_No_4_my.csv\n"
     ]
    }
   ],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エラスティックネット回帰\n",
    "from sklearn.linear_model import ElasticNet\n",
    "def model_ElasticNet(tr_X, tr_y):\n",
    "    model = ElasticNet(alpha = 0.5)\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "3.924977392584341\n",
      "*****\n",
      "4.063766212123566\n",
      "*****\n",
      "4.324165392645536\n",
      "*****\n",
      "4.190448437003381\n",
      "*****\n",
      "4.448839286789556\n",
      "*****\n",
      "4.109871421478162\n",
      "*****\n",
      "4.32841625127012\n",
      "*****\n",
      "4.5544400630224615\n",
      "*****\n",
      "4.422248031631271\n",
      "*****\n",
      "4.341653159801162\n",
      "*****\n",
      "4.083021464237497\n",
      "*****\n",
      "3.9350307119710273\n",
      "***\n",
      "***\n",
      "CV score is 4.227239818713173\n",
      "model_name is model_3_No_4_my.sav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_3_No_4_my.sav'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_ElasticNet(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_3_No_4_my.csv\n"
     ]
    }
   ],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#決定木\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def model_DecisionTreeRegressor(tr_X, tr_y):\n",
    "    model = DecisionTreeRegressor(random_state=0)\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.326165346495986\n",
      "*****\n",
      "4.462414464966567\n",
      "*****\n",
      "4.922056718056632\n",
      "*****\n",
      "4.788951570318616\n",
      "*****\n",
      "4.8938470870863044\n",
      "*****\n",
      "4.591816177519901\n",
      "*****\n",
      "4.621631385339154\n",
      "*****\n",
      "4.67887449368253\n",
      "*****\n",
      "4.554896893924791\n",
      "*****\n",
      "4.68522737748424\n",
      "*****\n",
      "4.826687713713649\n",
      "*****\n",
      "4.815273752744345\n",
      "***\n",
      "***\n",
      "CV score is 4.680653581777726\n",
      "model_name is model_4_No_4_my.sav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_4_No_4_my.sav'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_DecisionTreeRegressor(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_4_No_4_my.csv\n"
     ]
    }
   ],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "def model_LinearSVR(tr_X, tr_y):\n",
    "    model = LinearSVR(random_state=0)\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "3.9284594345637167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "5.298943795723864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.341179011306112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.458277071869066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "5.862964725531584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "5.180878567005831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.340345564727012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.763417258761026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.656161275020499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "4.663954379501769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "5.360107381027779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "8.299076547664155\n",
      "***\n",
      "***\n",
      "CV score is 5.096147084391868\n",
      "model_name is model_5_No_4_my.sav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_5_No_4_my.sav'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_LinearSVR(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#決定木\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def model_DecisionTreeRegressor(tr_X, tr_y):\n",
    "    model = DecisionTreeRegressor(random_state=0)\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_DecisionTreeRegressor(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#決定木\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def model_DecisionTreeRegressor(tr_X, tr_y):\n",
    "    model = DecisionTreeRegressor(random_state=0)\n",
    "    model.fit(tr_X,tr_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "sub_df_all = pd.DataFrame()\n",
    "valid_score_list = []\n",
    "#train_end_next_dateにはvalidationの一ヶ月の初めを入れる\n",
    "for d in month_range(dt(2014,8,1), dt(2015,8,1)):\n",
    "    make_data = make_tr_va_te(train_sta_wea, d)\n",
    "    train_notna = make_data.make_train_data()\n",
    "    valid_notna = make_data.make_valid_data()\n",
    "    test =make_data.make_test_data()\n",
    "    tr_X, tr_y, va_X, va_y = make_data.model_for_data(train_notna, valid_notna)\n",
    "    te_X = make_data.predict_for_data(test)\n",
    "    model = model_DecisionTreeRegressor(tr_X, tr_y)\n",
    "    model_name = model_name_list[0]\n",
    "    sub_df, valid_best_score = make_data.predict(model,model_name)\n",
    "    sub_df_all = pd.concat([sub_df_all, sub_df])\n",
    "    valid_score_list.append(valid_best_score)\n",
    "cv_score = sum(valid_score_list)/len(valid_score_list)\n",
    "print('***')\n",
    "print('***')\n",
    "print(f'CV score is {cv_score}')\n",
    "print(f'model_name is {model_name}')\n",
    "model_name_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_file_name = model_submit_dict[model_name]\n",
    "# sub_df_all.to_csv(output_path+submit_file_name, index=False, header=False)\n",
    "# print(submit_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "e = pd.read_csv('../output/submission_1_No_4_my.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193199, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8761</th>\n",
       "      <th>7.7221345203172405</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8762</td>\n",
       "      <td>7.712608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8763</td>\n",
       "      <td>7.703080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8764</td>\n",
       "      <td>7.693553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8765</td>\n",
       "      <td>7.684026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8766</td>\n",
       "      <td>7.674499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   8761  7.7221345203172405\n",
       "0  8762            7.712608\n",
       "1  8763            7.703080\n",
       "2  8764            7.693553\n",
       "3  8765            7.684026\n",
       "4  8766            7.674499"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
